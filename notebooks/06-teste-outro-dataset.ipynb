{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste com outro Dataset\n",
    "\n",
    "## Objetivo\n",
    "Recuperar o modelo treinado no notebook **05-treinamento_classificacao.ipynb** e aplicar o modelo já treinado a um novo conjunto de dados coletados num outro dia para verificar a acurácia.\n",
    "\n",
    "O dataset considerado neste teste usa outras coletas realizadas num outro dia por um período de 24 horas. As regras de coletas são as mesmas, coleta a cada 15 minutos durante 24horas.\n",
    "\n",
    "### Métricas Consideradas:\n",
    "- hash (identificador do contêiner)\n",
    "- Consumo de CPU (Valores de pico e tendência central)\n",
    "- Consumo de Memória (Valores de pico e tendência central)\n",
    "- Flavor (rótulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "import glob\n",
    "import os\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções Gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai a identificação do sistema a partir do nome do ambiente\n",
    "def extract_system_name(namespace):\n",
    "    environment = namespace.split('-')[-1]\n",
    "    system = namespace.split(f'-{environment}')[0]\n",
    "    return system\n",
    "\n",
    "# Cria os diretórios\n",
    "def create_folder(path):\n",
    "    try:\n",
    "       os.makedirs(path)\n",
    "    except FileExistsError:\n",
    "       # directory already exists\n",
    "       pass\n",
    "\n",
    "def hash(ambiente, pod):\n",
    "    return hashlib.md5(f'{ambiente}{pod}'.encode('utf-8')).hexdigest()\n",
    "\n",
    "# Regra de Rotulação\n",
    "def rotular_V2(cpu_MAX, cpu_MED, cpu_threshod, memoria_MAX, memoria_MED, memoria_threshod):\n",
    "    for f in range(0,11):\n",
    "        resultado_memoria = validar_flavor_para_memoria(memoria_MAX, memoria_MED, memoria_threshod, flavors[f])\n",
    "        resultado_cpu = validar_flavor_para_cpu(cpu_MAX, cpu_MED, cpu_threshod, flavors[f])\n",
    "        if resultado_memoria and resultado_cpu:\n",
    "            return flavors[f]['flavor']\n",
    "    return 'Nao classificado'\n",
    "\n",
    "def validar_flavor_para_memoria(memoria_MAX, memoria_MED, memoria_threshod, flavor):\n",
    "    return memoria_MAX + (memoria_threshod * 2 * (memoria_MAX - memoria_MED)) <= flavor['memoria']\n",
    "\n",
    "def validar_flavor_para_cpu(cpu_MAX, cpu_MED,cpu_threshod, flavor):\n",
    "    if cpu_MAX <= flavor['cpu']:\n",
    "        return True\n",
    "    return cpu_MAX - flavor['cpu'] <= cpu_threshod * 2 * (cpu_MAX - cpu_MED)\n",
    "\n",
    "# Predict\n",
    "def predict(model, exemplar):\n",
    "    del exemplar['hash']\n",
    "    del exemplar['flavor']    \n",
    "    print(f'Predicao para os parâmetros [{exemplar}] => flavor {model.predict(exemplar)[0]}')\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def cal_accuracy(y_test, y_pred):      \n",
    "    print(\"Confusion Matrix: \",\n",
    "        confusion_matrix(y_test, y_pred))\n",
    "      \n",
    "    print (\"Accuracy : \",\n",
    "    accuracy_score(y_test,y_pred)*100)\n",
    "      \n",
    "    print(\"Report : \",\n",
    "    classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento dos arquivos coletados (cpu, memoria, error, throttled)\n",
    "Pré-processamento dos arquivos originais coletados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_02300404112022.csv.gz\n",
      "cpu_16450504112022.csv.gz\n",
      "cpu_14000504112022.csv.gz\n",
      "cpu_12150504112022.csv.gz\n",
      "cpu_08150304112022.csv.gz\n",
      "cpu_22450603112022.csv.gz\n",
      "cpu_13150504112022.csv.gz\n",
      "cpu_05450504112022.csv.gz\n",
      "cpu_06300404112022.csv.gz\n",
      "cpu_11450404112022.csv.gz\n",
      "cpu_16300504112022.csv.gz\n",
      "cpu_18150604112022.csv.gz\n",
      "cpu_06450404112022.csv.gz\n",
      "cpu_23000603112022.csv.gz\n",
      "cpu_19150704112022.csv.gz\n",
      "cpu_21450904112022.csv.gz\n",
      "cpu_13450504112022.csv.gz\n",
      "cpu_18000704112022.csv.gz\n",
      "cpu_01000304112022.csv.gz\n",
      "cpu_01300504112022.csv.gz\n",
      "cpu_12000404112022.csv.gz\n",
      "cpu_23450503112022.csv.gz\n",
      "cpu_23300403112022.csv.gz\n",
      "cpu_16000604112022.csv.gz\n",
      "cpu_04000504112022.csv.gz\n",
      "cpu_23150303112022.csv.gz\n",
      "cpu_15450404112022.csv.gz\n",
      "cpu_12450504112022.csv.gz\n",
      "cpu_04300404112022.csv.gz\n",
      "cpu_07450404112022.csv.gz\n",
      "cpu_08450404112022.csv.gz\n",
      "cpu_11150504112022.csv.gz\n",
      "cpu_09000504112022.csv.gz\n",
      "cpu_17000504112022.csv.gz\n",
      "cpu_21001104112022.csv.gz\n",
      "cpu_09300604112022.csv.gz\n",
      "cpu_05300404112022.csv.gz\n",
      "cpu_09450504112022.csv.gz\n",
      "cpu_22150604112022.csv.gz\n",
      "cpu_01150404112022.csv.gz\n",
      "cpu_15300504112022.csv.gz\n",
      "cpu_10000504112022.csv.gz\n",
      "cpu_18300704112022.csv.gz\n",
      "cpu_14450504112022.csv.gz\n",
      "cpu_15000404112022.csv.gz\n",
      "cpu_00000404112022.csv.gz\n",
      "cpu_03300504112022.csv.gz\n",
      "cpu_07000504112022.csv.gz\n",
      "cpu_10450604112022.csv.gz\n",
      "cpu_20000404112022.csv.gz\n",
      "cpu_16150404112022.csv.gz\n",
      "cpu_18451204112022.csv.gz\n",
      "cpu_20150504112022.csv.gz\n",
      "cpu_15150504112022.csv.gz\n",
      "cpu_03150404112022.csv.gz\n",
      "cpu_17300804112022.csv.gz\n",
      "cpu_10150504112022.csv.gz\n",
      "cpu_10300504112022.csv.gz\n",
      "cpu_05150304112022.csv.gz\n",
      "cpu_21300904112022.csv.gz\n",
      "cpu_22300904112022.csv.gz\n",
      "cpu_02150404112022.csv.gz\n",
      "cpu_04150504112022.csv.gz\n",
      "cpu_20300804112022.csv.gz\n",
      "cpu_13000404112022.csv.gz\n",
      "cpu_01450604112022.csv.gz\n",
      "cpu_22000804112022.csv.gz\n",
      "cpu_03000504112022.csv.gz\n",
      "cpu_05000404112022.csv.gz\n",
      "cpu_03450704112022.csv.gz\n",
      "cpu_06000404112022.csv.gz\n",
      "cpu_08300404112022.csv.gz\n",
      "cpu_07150404112022.csv.gz\n",
      "cpu_00150804112022.csv.gz\n",
      "cpu_04450504112022.csv.gz\n",
      "cpu_12300404112022.csv.gz\n",
      "cpu_14150504112022.csv.gz\n",
      "cpu_19300404112022.csv.gz\n",
      "cpu_06150404112022.csv.gz\n",
      "cpu_14300604112022.csv.gz\n",
      "cpu_02000404112022.csv.gz\n",
      "cpu_11300404112022.csv.gz\n",
      "cpu_19450504112022.csv.gz\n",
      "cpu_08000404112022.csv.gz\n",
      "cpu_21151004112022.csv.gz\n",
      "cpu_19000704112022.csv.gz\n",
      "cpu_20451104112022.csv.gz\n",
      "cpu_13300404112022.csv.gz\n",
      "cpu_02450404112022.csv.gz\n",
      "cpu_07300404112022.csv.gz\n",
      "cpu_17150704112022.csv.gz\n",
      "cpu_09151904112022.csv.gz\n",
      "cpu_17450804112022.csv.gz\n",
      "cpu_11000404112022.csv.gz\n",
      "cpu_00450404112022.csv.gz\n",
      "cpu_00300504112022.csv.gz\n",
      "Fim processamento de CPU\n"
     ]
    }
   ],
   "source": [
    "# Processamento de arquivos de CPU\n",
    "header_list = [\"Sistema\", \"Ambiente\", \"Modulo\", \"Pod\", \"Uso_CPU\"]\n",
    "path_processados = '/dados/coletas_dia_2/cpu/processados'\n",
    "path_projeto = '/home/56740050368/Treinamento/IA-PUC_Minas/Trabalho_Cientifico/trabalho_puc_minas_2022'\n",
    "path_metricas = '/dados/coletas_dia_2/cpu/'\n",
    "csv_files = glob.glob(path_projeto+path_metricas+ \"*.gz\")\n",
    "\n",
    "# Cria diretorios\n",
    "create_folder(path_projeto+path_metricas)\n",
    "create_folder(path_projeto+path_processados)\n",
    "\n",
    "for file in csv_files:    \n",
    "    data = pd.read_csv(file, sep=';', header=None, names=header_list)\n",
    "    # obtem horario\n",
    "    filename = file.replace(path_projeto+path_metricas, \"\")\n",
    "    hora = int(filename[4:6])\n",
    "    min = int(filename[6:8])\n",
    "        \n",
    "    # acrescenta coluna de horário    \n",
    "    data['Hora'] = hora\n",
    "    \n",
    "    # acrescenta coluna de minuto    \n",
    "    data['Minuto'] = min\n",
    "    \n",
    "    # acrescenta coluna de hash\n",
    "    data['Hash'] = [hash(x, y) for x, y in zip(data['Ambiente'], data['Pod'])]\n",
    "    \n",
    "    # salva arquivo\n",
    "    data.to_csv(f'{path_projeto}{path_processados}/cpu_{hora}_{min}.csv', index=False)\n",
    "    \n",
    "print('Fim processamento de CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fim processsamento de Memoria\n"
     ]
    }
   ],
   "source": [
    "# Processamento de dados de memória\n",
    "header_list = [\"Sistema\", \"Ambiente\", \"Modulo\", \"Pod\", \"Uso_Memoria\"]\n",
    "path_processados = '/dados/coletas_dia_2/memoria/processados'\n",
    "path_metricas = '/dados/coletas_dia_2/memoria/'\n",
    "csv_files = glob.glob(path_projeto+path_metricas+ \"*.gz\")\n",
    "\n",
    "# Cria diretorios\n",
    "create_folder(path_projeto+path_metricas)\n",
    "create_folder(path_projeto+path_processados)\n",
    "\n",
    "for file in csv_files:    \n",
    "    data = pd.read_csv(file, sep=';', header=None, names=header_list)\n",
    "    # obtem horario\n",
    "    filename = file.replace(path_projeto+path_metricas, \"\")\n",
    "    hora = int(filename[7:9])\n",
    "    min = int(filename[9:11])\n",
    "        \n",
    "    # acrescenta coluna de horário    \n",
    "    data['Hora'] = hora\n",
    "    data['Minuto'] = min\n",
    "    # acrescenta coluna de hash\n",
    "    data['Hash'] = [hash(x, y) for x, y in zip(data['Ambiente'], data['Pod'])]\n",
    "    \n",
    "    # salva arquivo\n",
    "    data.to_csv(f'{path_projeto}{path_processados}/memoria_{hora}_{min}.csv', index=False)\n",
    "    \n",
    "print('Fim processsamento de Memoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fim processsamento de Erros de Memória\n"
     ]
    }
   ],
   "source": [
    "# Processamento da coleta de pods encerrados por estouro de memória\n",
    "header_list = [\"Sistema\", \"Ambiente\", \"Modulo\", \"Pod\", \"Error\", \"Qtd\"]\n",
    "path_processados = '/dados/coletas_dia_2/error/processados'\n",
    "path_metricas = '/dados/coletas_dia_2/error/'\n",
    "csv_files = glob.glob(path_projeto+path_metricas+ \"*.gz\")\n",
    "\n",
    "# Cria diretorios\n",
    "create_folder(path_projeto+path_metricas)\n",
    "create_folder(path_projeto+path_processados)\n",
    "\n",
    "for file in csv_files:    \n",
    "    data = pd.read_csv(file, sep=';', header=None, names=header_list)\n",
    "    # obtem horario\n",
    "    filename = file.replace(path_projeto+path_metricas, \"\")\n",
    "    \n",
    "    hora = int(filename[6:8])\n",
    "    min = int(filename[8:10])   \n",
    "        \n",
    "    # acrescenta coluna de horário    \n",
    "    data['Hora'] = hora\n",
    "    data['Minuto'] = min\n",
    "    # acrescenta coluna de hash\n",
    "    data['Hash'] = [hash(x, y) for x, y in zip(data['Ambiente'], data['Pod'])]\n",
    "    \n",
    "    # salva arquivo\n",
    "    data.to_csv(f'{path_projeto}{path_processados}/error_{hora}_{min}.csv', index=False)\n",
    "    \n",
    "print('Fim processsamento de Erros de Memória')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fim processsamento de CPU Throttled\n"
     ]
    }
   ],
   "source": [
    "# Processamento da coleta de pods encerrados por estouro de memória\n",
    "header_list = [\"Sistema\", \"Ambiente\", \"Modulo\", \"Pod\", \"Uso_CPU\"]\n",
    "path_processados = '/dados/coletas_dia_2/throttled/processados'\n",
    "path_metricas = '/dados/coletas_dia_2/throttled/'\n",
    "csv_files = glob.glob(path_projeto+path_metricas+ \"*.gz\")\n",
    "\n",
    "# Cria diretorios\n",
    "create_folder(path_projeto+path_metricas)\n",
    "create_folder(path_projeto+path_processados)\n",
    "\n",
    "for file in csv_files:    \n",
    "    data = pd.read_csv(file, sep=';', header=None, names=header_list)\n",
    "    # obtem horario\n",
    "    filename = file.replace(path_projeto+path_metricas, \"\")\n",
    "    hora = int(filename[14:16])\n",
    "    min = int(filename[16:18])   \n",
    "        \n",
    "    # acrescenta coluna de horário    \n",
    "    data['Hora'] = hora\n",
    "    data['Minuto'] = min\n",
    "    # acrescenta coluna de hash\n",
    "    data['Hash'] = [hash(x, y) for x, y in zip(data['Ambiente'], data['Pod'])]\n",
    "    \n",
    "    # salva arquivo\n",
    "    data.to_csv(f'{path_projeto}{path_processados}/cpu_throttled_{hora}_{min}.csv', index=False)\n",
    "    \n",
    "print('Fim processsamento de CPU Throttled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidação das Métricas num único arquivo por métrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerado arquivo consolidado da métrica de consumo de CPU\n"
     ]
    }
   ],
   "source": [
    "# Recuperar metricas dos arquivos processados\n",
    "path_processados = '/dados/coletas_dia_2/cpu/processados'\n",
    "csv_files = glob.glob(path_projeto+path_processados + \"/*.csv\")\n",
    "\n",
    "df_list = (pd.read_csv(file, skiprows = 1,header = None) for file in csv_files)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "big_cpu_df  = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Cria Tb Aplicações\n",
    "tb_medidas_cpu = big_cpu_df[[7, 5, 6, 4]].copy() # Colunas hash, hora, minuto, consumo_cpu\n",
    "\n",
    "# salva arquivo\n",
    "tb_medidas_cpu.to_csv(f'{path_projeto}/{path_processados}/consolidado_cpu.csv', index=False, header=['hash', 'hora', 'min', 'consumo_cpu']) # \n",
    "    \n",
    "print('Gerado arquivo consolidado da métrica de consumo de CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerado arquivo consolidado da métrica de consumo de Memória\n"
     ]
    }
   ],
   "source": [
    "# Recuperar metricas dos arquivos processados\n",
    "path_processados = '/dados/coletas_dia_2/memoria/processados'\n",
    "csv_files = glob.glob(path_projeto+path_processados + \"/*.csv\")\n",
    "\n",
    "df_list = (pd.read_csv(file, skiprows = 1,header = None) for file in csv_files)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "big_memoria_df  = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Cria Tb Aplicações\n",
    "tb_medidas_memoria = big_memoria_df[[7, 5, 6, 4]].copy() # Colunas hash, hora, minuto, consumo_memoria\n",
    "\n",
    "# salva arquivo\n",
    "tb_medidas_memoria.to_csv(f'{path_projeto}/{path_processados}/consolidado_memoria.csv', index=False, header=['hash', 'hora', 'min', 'consumo_memoria']) \n",
    "    \n",
    "print('Gerado arquivo consolidado da métrica de consumo de Memória')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerado arquivo consolidado da métrica de erros de Memória\n"
     ]
    }
   ],
   "source": [
    "# Recuperar metricas dos arquivos processados\n",
    "path_processados = '/dados/coletas_dia_2/error/processados'\n",
    "csv_files = glob.glob(path_projeto+path_processados + \"/*.csv\")\n",
    "\n",
    "df_list = (pd.read_csv(file, skiprows = 1,header = None) for file in csv_files)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "big_error_df  = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Cria Tb Aplicações\n",
    "tb_medidas_error = big_error_df[[8, 6, 7, 5]].copy() # Colunas hash, hora, minuto, qtd de erros\n",
    "\n",
    "# salva arquivo\n",
    "tb_medidas_error.to_csv(f'{path_projeto}/{path_processados}/consolidado_error.csv', index=False, header=['hash', 'hora', 'min', 'qtd']) \n",
    "    \n",
    "print('Gerado arquivo consolidado da métrica de erros de Memória')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerado arquivo consolidado da métrica de consumo excessivo de cpu\n"
     ]
    }
   ],
   "source": [
    "# Recuperar metricas dos arquivos processados\n",
    "path_processados = '/dados/coletas_dia_2/throttled/processados'\n",
    "csv_files = glob.glob(path_projeto+path_processados + \"/*.csv\")\n",
    "\n",
    "df_list = (pd.read_csv(file, skiprows = 1,header = None) for file in csv_files)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "big_throttled_df  = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Cria Tb Aplicações\n",
    "tb_medidas_throttled = big_throttled_df[[7, 5, 6, 4]].copy() # Colunas hash, hora, minuto, qtd de erros\n",
    "\n",
    "# salva arquivo\n",
    "tb_medidas_throttled.to_csv(f'{path_projeto}/{path_processados}/consolidado_cpu_throttled.csv', index=False, header=['hash', 'hora', 'min', 'consumo_cpu']) \n",
    "    \n",
    "print('Gerado arquivo consolidado da métrica de consumo excessivo de cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregação dos Dados e Limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerados valores de CPU: valor de pico e mediana\n"
     ]
    }
   ],
   "source": [
    "## Agregação dos valores de CPU\n",
    "path_processados_cpu = '/dados/coletas_dia_2/cpu/processados'\n",
    "csv_file_consolidado_cpu = f'{path_projeto}{path_processados_cpu}/consolidado_cpu.csv'\n",
    "df_consolidado_cpu = pd.read_csv(csv_file_consolidado_cpu, sep=',',decimal='.')\n",
    "# Remoção dos valores zerados de consumo de CPU\n",
    "df_consolidado_cpu = df_consolidado_cpu[df_consolidado_cpu['consumo_cpu'] > 0]\n",
    "# Transformação do consumo de CPU em miliCPU (miliCPU) (x 1000)\n",
    "df_consolidado_cpu['consumo_cpu'] = df_consolidado_cpu['consumo_cpu'] * 1000\n",
    "# Exclui as colunas de hora e minuto\n",
    "del df_consolidado_cpu['hora']\n",
    "del df_consolidado_cpu['min']\n",
    "# Realiza agrupamento do consumo de CPU por aplicação, identififcado pela coluna hash. \n",
    "# Será considerado os valores de pico (max) por aplicação\n",
    "df_group_by_max_cpu = df_consolidado_cpu.groupby(['hash']).max()\n",
    "# Reseta o índice\n",
    "df_group_by_max_cpu.reset_index(inplace=True)\n",
    "df_group_by_max_cpu = df_group_by_max_cpu.rename(columns = {'consumo_cpu':'pico_cpu'})\n",
    "# Agrupa as aplicações e agrega pelo valor da mediana dos valores de consumo de CPU por aplicação\n",
    "df_group_by_med_cpu = df_consolidado_cpu.groupby(['hash']).median()\n",
    "# Reseta o índice\n",
    "df_group_by_med_cpu.reset_index(inplace=True)\n",
    "df_group_by_med_cpu = df_group_by_med_cpu.rename(columns = {'consumo_cpu':'mediana_cpu'})\n",
    "print('Gerados valores de CPU: valor de pico e mediana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerados valores de Memoria: valor de pico e mediana\n"
     ]
    }
   ],
   "source": [
    "## Agregação dos dados de Memória\n",
    "path_processados_memoria = '/dados/coletas_dia_2/memoria/processados'\n",
    "csv_file_consolidado_memoria = f'{path_projeto}{path_processados_memoria}/consolidado_memoria.csv'\n",
    "df_consolidado_memoria = pd.read_csv(csv_file_consolidado_memoria, sep=',',decimal='.')\n",
    "# Remove os valores zerados de consumo de memória\n",
    "df_consolidado_memoria = df_consolidado_memoria[df_consolidado_memoria['consumo_memoria'] > 0]\n",
    "# Exclui a coluna de hora e minuto\n",
    "del df_consolidado_memoria['hora']\n",
    "del df_consolidado_memoria['min']\n",
    "## Connverte o valor de consumo de memória de bytes para MB\n",
    "df_consolidado_memoria['consumo_memoria'] = df_consolidado_memoria['consumo_memoria'] / (1024 * 1024)\n",
    "# Obtenção do Pico de Memória por aplicação\n",
    "df_group_by_max_memoria = df_consolidado_memoria.groupby(['hash']).max()\n",
    "# Reseta o índice\n",
    "df_group_by_max_memoria.reset_index(inplace=True)\n",
    "df_group_by_max_memoria = df_group_by_max_memoria.rename(columns = {'consumo_memoria':'pico_memoria'})\n",
    "# Obtenção da Mediana de Consumo de Memória\n",
    "df_group_by_med_memoria = df_consolidado_memoria.groupby(['hash']).median()\n",
    "# Reseta o índice\n",
    "df_group_by_med_memoria.reset_index(inplace=True)\n",
    "df_group_by_med_memoria = df_group_by_med_memoria.rename(columns = {'consumo_memoria':'mediana_memoria'})\n",
    "print('Gerados valores de Memoria: valor de pico e mediana')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregação das métricas num único dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>mediana_cpu</th>\n",
       "      <th>pico_cpu</th>\n",
       "      <th>mediana_memoria</th>\n",
       "      <th>pico_memoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00069f104213910f2b16348ed769f2d0</td>\n",
       "      <td>4.224617</td>\n",
       "      <td>4.224617</td>\n",
       "      <td>726.539062</td>\n",
       "      <td>726.539062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008019539e8167e69236ac2ea9ae47e</td>\n",
       "      <td>0.842479</td>\n",
       "      <td>3.531902</td>\n",
       "      <td>2.429688</td>\n",
       "      <td>6.867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00115d136a63167e961d60147809aff7</td>\n",
       "      <td>147.528715</td>\n",
       "      <td>281.290402</td>\n",
       "      <td>199.113281</td>\n",
       "      <td>199.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0012e711c5c46e63dc1e77562687f116</td>\n",
       "      <td>74.683044</td>\n",
       "      <td>6394.682793</td>\n",
       "      <td>318.091797</td>\n",
       "      <td>498.496094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00171f1ecb4cb384c73b460e424033ae</td>\n",
       "      <td>8.429162</td>\n",
       "      <td>25.210683</td>\n",
       "      <td>129.312500</td>\n",
       "      <td>133.417969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13225</th>\n",
       "      <td>ffd950eb6ceeacfbd2f239eb34679cbe</td>\n",
       "      <td>1.014986</td>\n",
       "      <td>3.279584</td>\n",
       "      <td>625.476562</td>\n",
       "      <td>639.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13226</th>\n",
       "      <td>ffdb935e97a6dd0530958526e31dc129</td>\n",
       "      <td>3.124941</td>\n",
       "      <td>7.315109</td>\n",
       "      <td>649.609375</td>\n",
       "      <td>1022.175781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13227</th>\n",
       "      <td>ffe7450b3571c80c26389cd403b6017c</td>\n",
       "      <td>3.608737</td>\n",
       "      <td>11.933037</td>\n",
       "      <td>172.384766</td>\n",
       "      <td>248.261719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13228</th>\n",
       "      <td>fff13383e3a6e8b8cc87a597f9fc8272</td>\n",
       "      <td>3.963118</td>\n",
       "      <td>51.979386</td>\n",
       "      <td>3819.111328</td>\n",
       "      <td>3847.378906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13229</th>\n",
       "      <td>fff602eaae3069b08241eb3d38862349</td>\n",
       "      <td>172.549039</td>\n",
       "      <td>257.546498</td>\n",
       "      <td>3014.927734</td>\n",
       "      <td>4094.632812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13230 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   hash  mediana_cpu     pico_cpu  \\\n",
       "0      00069f104213910f2b16348ed769f2d0     4.224617     4.224617   \n",
       "1      0008019539e8167e69236ac2ea9ae47e     0.842479     3.531902   \n",
       "2      00115d136a63167e961d60147809aff7   147.528715   281.290402   \n",
       "3      0012e711c5c46e63dc1e77562687f116    74.683044  6394.682793   \n",
       "4      00171f1ecb4cb384c73b460e424033ae     8.429162    25.210683   \n",
       "...                                 ...          ...          ...   \n",
       "13225  ffd950eb6ceeacfbd2f239eb34679cbe     1.014986     3.279584   \n",
       "13226  ffdb935e97a6dd0530958526e31dc129     3.124941     7.315109   \n",
       "13227  ffe7450b3571c80c26389cd403b6017c     3.608737    11.933037   \n",
       "13228  fff13383e3a6e8b8cc87a597f9fc8272     3.963118    51.979386   \n",
       "13229  fff602eaae3069b08241eb3d38862349   172.549039   257.546498   \n",
       "\n",
       "       mediana_memoria  pico_memoria  \n",
       "0           726.539062    726.539062  \n",
       "1             2.429688      6.867188  \n",
       "2           199.113281    199.507812  \n",
       "3           318.091797    498.496094  \n",
       "4           129.312500    133.417969  \n",
       "...                ...           ...  \n",
       "13225       625.476562    639.003906  \n",
       "13226       649.609375   1022.175781  \n",
       "13227       172.384766    248.261719  \n",
       "13228      3819.111328   3847.378906  \n",
       "13229      3014.927734   4094.632812  \n",
       "\n",
       "[13230 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizando o join do consumo de memória e cpu\n",
    "# Agregação das colunas de valores mediana e pico da CPU\n",
    "df_group_by_cpu = pd.concat([df_group_by_med_cpu.set_index('hash'),df_group_by_max_cpu.set_index('hash')], \n",
    "                            axis=1, join='inner').reset_index()\n",
    "\n",
    "# Agregação das colunas de valores mediana e pico da Memoria\n",
    "df_group_by_memoria = pd.concat([df_group_by_med_memoria.set_index('hash'),df_group_by_max_memoria.set_index('hash')], \n",
    "                                axis=1, join='inner').reset_index()\n",
    "\n",
    "# Agregação das colunas de CPU e Memoria\n",
    "df_group_by_cpu_memoria = pd.concat([df_group_by_cpu.set_index('hash'),df_group_by_memoria.set_index('hash')], \n",
    "                                    axis=1, join='inner').reset_index()\n",
    "df_group_by_cpu_memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção da aplicações com execuções além dos recursos de cpu e memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removido aplicacoes (conteineres) com execuções além dos recursos de cpu e memoria\n"
     ]
    }
   ],
   "source": [
    "## Agrupa as aplicacoes com estouro de memória\n",
    "path_processados_error = '/dados/coletas_dia_2/error/processados'\n",
    "csv_file_consolidado_error = f'{path_projeto}{path_processados_error}/consolidado_error.csv'\n",
    "df_consolidado_error_memoria = pd.read_csv(csv_file_consolidado_error, sep=',',decimal='.')\n",
    "## Agrega as aplicações pelo o hash de identificação\n",
    "df_aplicacoes_error_memoria = df_consolidado_error_memoria['hash'].unique()\n",
    "## Remove as aplicaçoes com erro de memória do dataframe consolidado\n",
    "df_group_by_cpu_memoria = df_group_by_cpu_memoria[~df_group_by_cpu_memoria['hash'].isin(df_aplicacoes_error_memoria)]\n",
    "## Agrupa as aplicacoes com excesso de cpu (throttled)\n",
    "path_processados_throttled = '/dados/coletas_dia_2/throttled/processados'\n",
    "csv_file_consolidado_throttled = f'{path_projeto}{path_processados_throttled}/consolidado_cpu_throttled.csv'\n",
    "df_consolidado_throttled = pd.read_csv(csv_file_consolidado_throttled, sep=',',decimal='.')\n",
    "## Agrega as aplicações pelo o hash de identificação\n",
    "df_consolidado_throttled = df_consolidado_throttled['hash'].unique()\n",
    "## Remove as aplicaçoes com erro de memória do dataframe consolidado\n",
    "df_group_by_cpu_memoria = df_group_by_cpu_memoria[~df_group_by_cpu_memoria['hash'].isin(df_consolidado_throttled)]\n",
    "df_group_by_cpu_memoria.reset_index(drop=True)\n",
    "print('Removido aplicacoes (conteineres) com execuções além dos recursos de cpu e memoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remoção de valores discrepantes (acima do flavor f10)\n",
    "df_group_by_cpu_memoria = df_group_by_cpu_memoria[df_group_by_cpu_memoria['pico_cpu'] < 10.8]\n",
    "df_group_by_cpu_memoria = df_group_by_cpu_memoria[df_group_by_cpu_memoria['pico_memoria'] < 550]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotulação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotulacao Completa!\n"
     ]
    }
   ],
   "source": [
    "## Flavors\n",
    "flavors = [{'id': '0', 'flavor': 'f0', 'cpu': 1, 'memoria': 50},\n",
    "           {'id': '1', 'flavor': 'f1', 'cpu': 2, 'memoria': 100},\n",
    "           {'id': '2', 'flavor': 'f2', 'cpu': 3, 'memoria': 150},\n",
    "           {'id': '3', 'flavor': 'f3', 'cpu': 4, 'memoria': 200},\n",
    "           {'id': '4', 'flavor': 'f4', 'cpu': 5, 'memoria': 250},\n",
    "           {'id': '5', 'flavor': 'f5', 'cpu': 6, 'memoria': 300},\n",
    "           {'id': '6', 'flavor': 'f6', 'cpu': 7, 'memoria': 350},\n",
    "           {'id': '7', 'flavor': 'f7', 'cpu': 8, 'memoria': 400},\n",
    "           {'id': '8', 'flavor': 'f8', 'cpu': 9, 'memoria': 450},\n",
    "           {'id': '9', 'flavor': 'f9', 'cpu': 10, 'memoria': 500},\n",
    "           {'id': '10', 'flavor': 'f10', 'cpu': 11, 'memoria': 550}]\n",
    "\n",
    "## Thresholds\n",
    "cpu_threshod = 0.05\n",
    "memoria_threshod = 0.1\n",
    "\n",
    "## Atribuição do flavor\n",
    "df_group_by_cpu_memoria['flavor'] = df_group_by_cpu_memoria.apply(lambda x: rotular_V2(x.pico_cpu, x.mediana_cpu, cpu_threshod, x.pico_memoria, x.mediana_memoria, memoria_threshod), axis=1)\n",
    "print ('Rotulacao Completa!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de conteineres não classificados  8\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade de conteineres não classificados ', len(df_group_by_cpu_memoria[df_group_by_cpu_memoria['flavor']=='Nao classificado']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>mediana_cpu</th>\n",
       "      <th>pico_cpu</th>\n",
       "      <th>mediana_memoria</th>\n",
       "      <th>pico_memoria</th>\n",
       "      <th>flavor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>3671116ef74cf976975f51b8b0ab09ef</td>\n",
       "      <td>1.042284</td>\n",
       "      <td>5.306334</td>\n",
       "      <td>365.917969</td>\n",
       "      <td>522.871094</td>\n",
       "      <td>Nao classificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>4f678b632d4254bd544b0d3e07e6e211</td>\n",
       "      <td>0.837475</td>\n",
       "      <td>7.973825</td>\n",
       "      <td>523.533203</td>\n",
       "      <td>545.691406</td>\n",
       "      <td>Nao classificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>625e07aab82c92277fb9bcc5c0f6e9d0</td>\n",
       "      <td>0.578412</td>\n",
       "      <td>1.000068</td>\n",
       "      <td>506.031250</td>\n",
       "      <td>543.398438</td>\n",
       "      <td>Nao classificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5208</th>\n",
       "      <td>635bdbabc20d34ef82c0a91792517543</td>\n",
       "      <td>6.048417</td>\n",
       "      <td>8.734129</td>\n",
       "      <td>531.056641</td>\n",
       "      <td>547.156250</td>\n",
       "      <td>Nao classificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7930</th>\n",
       "      <td>97bc09bffcb57c15b8526c680fe289b9</td>\n",
       "      <td>3.956844</td>\n",
       "      <td>3.956844</td>\n",
       "      <td>270.191406</td>\n",
       "      <td>538.441406</td>\n",
       "      <td>Nao classificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8589</th>\n",
       "      <td>a500dc5fe5152302fecc27136bcbb5f8</td>\n",
       "      <td>2.273550</td>\n",
       "      <td>6.400257</td>\n",
       "      <td>533.439453</td>\n",
       "      <td>547.523438</td>\n",
       "      <td>Nao classificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>bdf057ab2d50a5d866d7e53584f15ba7</td>\n",
       "      <td>2.195545</td>\n",
       "      <td>7.632336</td>\n",
       "      <td>542.574219</td>\n",
       "      <td>549.269531</td>\n",
       "      <td>Nao classificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12028</th>\n",
       "      <td>e8171b196d0a370e3934cb43b9a118f3</td>\n",
       "      <td>2.105516</td>\n",
       "      <td>6.049615</td>\n",
       "      <td>542.015625</td>\n",
       "      <td>549.546875</td>\n",
       "      <td>Nao classificado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   hash  mediana_cpu  pico_cpu  \\\n",
       "2881   3671116ef74cf976975f51b8b0ab09ef     1.042284  5.306334   \n",
       "4182   4f678b632d4254bd544b0d3e07e6e211     0.837475  7.973825   \n",
       "5148   625e07aab82c92277fb9bcc5c0f6e9d0     0.578412  1.000068   \n",
       "5208   635bdbabc20d34ef82c0a91792517543     6.048417  8.734129   \n",
       "7930   97bc09bffcb57c15b8526c680fe289b9     3.956844  3.956844   \n",
       "8589   a500dc5fe5152302fecc27136bcbb5f8     2.273550  6.400257   \n",
       "9874   bdf057ab2d50a5d866d7e53584f15ba7     2.195545  7.632336   \n",
       "12028  e8171b196d0a370e3934cb43b9a118f3     2.105516  6.049615   \n",
       "\n",
       "       mediana_memoria  pico_memoria            flavor  \n",
       "2881        365.917969    522.871094  Nao classificado  \n",
       "4182        523.533203    545.691406  Nao classificado  \n",
       "5148        506.031250    543.398438  Nao classificado  \n",
       "5208        531.056641    547.156250  Nao classificado  \n",
       "7930        270.191406    538.441406  Nao classificado  \n",
       "8589        533.439453    547.523438  Nao classificado  \n",
       "9874        542.574219    549.269531  Nao classificado  \n",
       "12028       542.015625    549.546875  Nao classificado  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remove os não classificados\n",
    "## Os não classificados deveriam estar num próximo flavor f11, caso existisse. Neste caso serão removidos.\n",
    "df_nao_classificado = df_group_by_cpu_memoria[df_group_by_cpu_memoria['flavor']=='Nao classificado']\n",
    "df_nao_classificado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação dos Dados com o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregado o modelo :  DecisionTreeClassifier(criterion='entropy')\n"
     ]
    }
   ],
   "source": [
    "## Carrega o modelo\n",
    "# Loading the saved decision tree model pickle\n",
    "import pickle\n",
    "decision_tree_pkl_filename = 'decision_tree_classifier_entropy.pkl'\n",
    "decision_tree_model_pkl = open(decision_tree_pkl_filename, 'rb')\n",
    "decision_tree_model = pickle.load(decision_tree_model_pkl)\n",
    "print (\"Carregado o modelo : \", decision_tree_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predições e Validação com o novo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>mediana_cpu</th>\n",
       "      <th>pico_cpu</th>\n",
       "      <th>mediana_memoria</th>\n",
       "      <th>pico_memoria</th>\n",
       "      <th>flavor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008019539e8167e69236ac2ea9ae47e</td>\n",
       "      <td>0.842479</td>\n",
       "      <td>3.531902</td>\n",
       "      <td>2.429688</td>\n",
       "      <td>6.867188</td>\n",
       "      <td>f3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00192f6f6f4e5a93d8d562202c6d0227</td>\n",
       "      <td>0.931205</td>\n",
       "      <td>1.026860</td>\n",
       "      <td>485.326172</td>\n",
       "      <td>485.457031</td>\n",
       "      <td>f9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00397e755d86f88d58f23419ce8ba8e8</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>11.078125</td>\n",
       "      <td>11.082031</td>\n",
       "      <td>f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>003c3255c6f292d40085b45189c83b23</td>\n",
       "      <td>0.115936</td>\n",
       "      <td>0.594569</td>\n",
       "      <td>241.992188</td>\n",
       "      <td>242.007812</td>\n",
       "      <td>f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>004156954736d58869a3a2e1d5e197e8</td>\n",
       "      <td>5.825029</td>\n",
       "      <td>8.259004</td>\n",
       "      <td>346.830078</td>\n",
       "      <td>347.882812</td>\n",
       "      <td>f8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                hash  mediana_cpu  pico_cpu  mediana_memoria  \\\n",
       "1   0008019539e8167e69236ac2ea9ae47e     0.842479  3.531902         2.429688   \n",
       "5   00192f6f6f4e5a93d8d562202c6d0227     0.931205  1.026860       485.326172   \n",
       "8   00397e755d86f88d58f23419ce8ba8e8     0.001332  0.002303        11.078125   \n",
       "9   003c3255c6f292d40085b45189c83b23     0.115936  0.594569       241.992188   \n",
       "10  004156954736d58869a3a2e1d5e197e8     5.825029  8.259004       346.830078   \n",
       "\n",
       "    pico_memoria flavor  \n",
       "1       6.867188     f3  \n",
       "5     485.457031     f9  \n",
       "8      11.082031     f0  \n",
       "9     242.007812     f4  \n",
       "10    347.882812     f8  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group_by_cpu_memoria.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicao para os parâmetros [   mediana_cpu  pico_cpu  mediana_memoria  pico_memoria\n",
      "5     0.931205   1.02686       485.326172    485.457031] => flavor f9\n"
     ]
    }
   ],
   "source": [
    "# Teste com escolha manual\n",
    "exemplar = df_group_by_cpu_memoria[df_group_by_cpu_memoria['hash']=='00192f6f6f4e5a93d8d562202c6d0227']\n",
    "predict(decision_tree_model, exemplar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicao para os parâmetros [    mediana_cpu  pico_cpu  mediana_memoria  pico_memoria\n",
      "10     5.825029  8.259004       346.830078    347.882812] => flavor f7\n"
     ]
    }
   ],
   "source": [
    "# Teste com escolha manual\n",
    "exemplar = df_group_by_cpu_memoria[df_group_by_cpu_memoria['hash']=='004156954736d58869a3a2e1d5e197e8']\n",
    "predict(decision_tree_model, exemplar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de conteineres não classificados  0\n"
     ]
    }
   ],
   "source": [
    "## Remove não classificados\n",
    "for i in df_nao_classificado.index:\n",
    "    df_group_by_cpu_memoria = df_group_by_cpu_memoria.drop([i])\n",
    "print('Quantidade de conteineres não classificados ', len(df_group_by_cpu_memoria[df_group_by_cpu_memoria['flavor']=='Nao classificado']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9748723545077768"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## X_test = df_group_by_cpu_memoria[['mediana_cpu', 'pico_cpu', 'mediana_memoria', 'pico_memoria']]\n",
    "y_test = df_group_by_cpu_memoria[['flavor']]\n",
    "allScores = cross_val_score(decision_tree_model, X_test, y_test , cv=10)\n",
    "# cross_val_score retorna array com as 10 validações\n",
    "allScores.mean() # tomamos a média do score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  [[1650    2    0    0    0    0    0    0    0    0    0]\n",
      " [   5 1053    0   12    0    0    0    0    0    0    0]\n",
      " [   0    0  291    0    0    0    0    0    0    0   16]\n",
      " [   0    9    0  718    5    0    0    0    0    0    0]\n",
      " [   0    0    0   12  505   12    0    0    0    0    0]\n",
      " [   0    0    0    0    6  463   12    0    0    0    0]\n",
      " [   0    0    0    0    0    8  435    4    0    0    0]\n",
      " [   0    0    0    0    0    0   10  442   10    0    0]\n",
      " [   0    0    0    0    0    0    0   11  516   11    0]\n",
      " [   0    0    0    0    0    0    0    0   16  493    6]\n",
      " [   0    0    8    0    0    0    0    0    0    8  374]]\n",
      "Accuracy :  97.4308577846413\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "          f0       1.00      1.00      1.00      1652\n",
      "          f1       0.99      0.98      0.99      1070\n",
      "         f10       0.97      0.95      0.96       307\n",
      "          f2       0.97      0.98      0.97       732\n",
      "          f3       0.98      0.95      0.97       529\n",
      "          f4       0.96      0.96      0.96       481\n",
      "          f5       0.95      0.97      0.96       447\n",
      "          f6       0.97      0.96      0.96       462\n",
      "          f7       0.95      0.96      0.96       538\n",
      "          f8       0.96      0.96      0.96       515\n",
      "          f9       0.94      0.96      0.95       390\n",
      "\n",
      "    accuracy                           0.97      7123\n",
      "   macro avg       0.97      0.97      0.97      7123\n",
      "weighted avg       0.97      0.97      0.97      7123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "y_pred = decision_tree_model.predict(X_test)\n",
    "cal_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
